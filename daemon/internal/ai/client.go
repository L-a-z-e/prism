package ai

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"strings"
	"time"
)

type Client interface {
	GenerateCode(ctx context.Context, prompt string) (string, error)
	ReviewCode(ctx context.Context, code string) (string, error)
	GenerateCodeStream(ctx context.Context, prompt string, callback func(chunk string) error) error
}

// ============================================================================
// Ollama Client - Ïã§Ï†ú DeepSeek/Î°úÏª¨ LLM ÏÇ¨Ïö©
// ============================================================================

type OllamaClient struct {
	baseURL string
	model   string
	timeout time.Duration
	client  *http.Client
}

func NewOllamaClient() *OllamaClient {
	baseURL := os.Getenv("OLLAMA_URL")
	if baseURL == "" {
		baseURL = "http://localhost:11434"
	}

	model := os.Getenv("OLLAMA_MODEL")
	if model == "" {
		model = "deepseek-r1:14b"
	}

	timeout := 300 * time.Second
	if timeoutEnv := os.Getenv("OLLAMA_TIMEOUT"); timeoutEnv != "" {
		if d, err := time.ParseDuration(timeoutEnv); err == nil {
			timeout = d
		}
	}

	return &OllamaClient{
		baseURL: baseURL,
		model:   model,
		timeout: timeout,
		client: &http.Client{
			Timeout: timeout,
		},
	}
}

type OllamaRequest struct {
	Model   string                 `json:"model"`
	Prompt  string                 `json:"prompt"`
	Stream  bool                   `json:"stream"`
	Options map[string]interface{} `json:"options,omitempty"`
}

type OllamaResponse struct {
	Model         string `json:"model"`
	Response      string `json:"response"`
	Done          bool   `json:"done"`
	Context       []int  `json:"context,omitempty"`
	TotalDuration int64  `json:"total_duration,omitempty"`
}

// GenerateCode - ÎπÑÏä§Ìä∏Î¶¨Î∞ç Î∞©Ïãù (Ï†ÑÏ≤¥ ÏùëÎãµ ÎåÄÍ∏∞)
func (c *OllamaClient) GenerateCode(ctx context.Context, prompt string) (string, error) {
	var result string
	var lastErr error

	// Ïû¨ÏãúÎèÑ Î°úÏßÅ (ÏµúÎåÄ 3Ìöå)
	for attempt := 1; attempt <= 3; attempt++ {
		req := OllamaRequest{
			Model:  c.model,
			Prompt: prompt,
			Stream: false,
			Options: map[string]interface{}{
				"temperature": 0.1,
				"top_p":       0.9,
				"top_k":       40,
			},
		}

		jsonData, err := json.Marshal(req)
		if err != nil {
			return "", fmt.Errorf("failed to marshal request: %w", err)
		}

		httpReq, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/generate", bytes.NewBuffer(jsonData))
		if err != nil {
			return "", fmt.Errorf("failed to create request: %w", err)
		}
		httpReq.Header.Set("Content-Type", "application/json")

		resp, err := c.client.Do(httpReq)
		if err != nil {
			lastErr = err
			if attempt < 3 {
				// exponential backoff
				backoff := time.Duration(1<<uint(attempt-1)) * time.Second
				select {
				case <-time.After(backoff):
					continue
				case <-ctx.Done():
					return "", ctx.Err()
				}
			}
			continue
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			lastErr = fmt.Errorf("ollama API error (status %d): %s", resp.StatusCode, string(body))
			if attempt < 3 && resp.StatusCode >= 500 {
				backoff := time.Duration(1<<uint(attempt-1)) * time.Second
				select {
				case <-time.After(backoff):
					continue
				case <-ctx.Done():
					return "", ctx.Err()
				}
			}
			continue
		}

		body, err := io.ReadAll(resp.Body)
		if err != nil {
			lastErr = fmt.Errorf("failed to read response: %w", err)
			continue
		}

		var ollamaResp OllamaResponse
		if err := json.Unmarshal(body, &ollamaResp); err != nil {
			lastErr = fmt.Errorf("failed to unmarshal response: %w", err)
			continue
		}

		result = ollamaResp.Response
		return result, nil
	}

	return "", fmt.Errorf("all retry attempts failed: %w", lastErr)
}

// GenerateCodeStream - Ïä§Ìä∏Î¶¨Î∞ç Î∞©Ïãù (Ïã§ÏãúÍ∞Ñ ÏùëÎãµ)
func (c *OllamaClient) GenerateCodeStream(ctx context.Context, prompt string, callback func(chunk string) error) error {
	req := OllamaRequest{
		Model:  c.model,
		Prompt: prompt,
		Stream: true, // Ïä§Ìä∏Î¶¨Î∞ç ÌôúÏÑ±Ìôî
		Options: map[string]interface{}{
			"temperature": 0.1,
			"top_p":       0.9,
			"top_k":       40,
		},
	}

	jsonData, err := json.Marshal(req)
	if err != nil {
		return fmt.Errorf("failed to marshal request: %w", err)
	}

	httpReq, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/generate", bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("failed to create request: %w", err)
	}
	httpReq.Header.Set("Content-Type", "application/json")

	resp, err := c.client.Do(httpReq)
	if err != nil {
		return fmt.Errorf("failed to call ollama API: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("ollama API error (status %d): %s", resp.StatusCode, string(body))
	}

	// Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµ Ï≤òÎ¶¨
	scanner := bufio.NewScanner(resp.Body)
	for scanner.Scan() {
		select {
		case <-ctx.Done():
			return ctx.Err()
		default:
		}

		line := scanner.Bytes()
		var streamResp OllamaResponse
		if err := json.Unmarshal(line, &streamResp); err != nil {
			continue
		}

		if streamResp.Response != "" {
			if err := callback(streamResp.Response); err != nil {
				return err
			}
		}
	}

	return scanner.Err()
}

func (c *OllamaClient) ReviewCode(ctx context.Context, code string) (string, error) {
	prompt := fmt.Sprintf(`Review the following code and provide detailed feedback in Korean:

Code:
%s

Please provide:
1. Code quality assessment
2. Potential bugs or issues
3. Performance improvements
4. Best practice suggestions`, code)

	return c.GenerateCode(ctx, prompt)
}

// ============================================================================
// Mock Client - ÌÖåÏä§Ìä∏Ïö© (OLLAMA_MOCK=true ÎòêÎäî Ollama Ïó∞Í≤∞ Î∂àÍ∞ÄÎä• Ïãú)
// ============================================================================

type MockClient struct{}

func NewMockClient() *MockClient {
	return &MockClient{}
}

func (c *MockClient) GenerateCode(ctx context.Context, prompt string) (string, error) {
	// Ïã§Ï†ú ÏöîÏ≤≠ ÌùîÏ†ÅÏùÑ Î≥¥Ïù¥Í∏∞ ÏúÑÌï¥ ÏùºÎ∂Ä ÌîÑÎ°¨ÌîÑÌä∏ ÎÇ¥Ïö© Î∞òÏòÅ
	lang := "Java"
	if strings.Contains(prompt, "TypeScript") || strings.Contains(prompt, "Vue") {
		lang = "TypeScript"
	} else if strings.Contains(prompt, "Python") {
		lang = "Python"
	}

	codeSnippet := fmt.Sprintf(`// Mock generated code (%s)
// Based on prompt: %s

package com.example.demo;

import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("/api")
public class DemoController {
    
    @GetMapping("/hello")
    public String hello() {
        return "Hello from Mock AI!";
    }
}`, lang, strings.TrimSpace(prompt)[:50])

	// Mock Ïã§Ìñâ ÏãúÍ∞Ñ ÏãúÎÆ¨Î†àÏù¥ÏÖò
	select {
	case <-time.After(500 * time.Millisecond):
		return codeSnippet, nil
	case <-ctx.Done():
		return "", ctx.Err()
	}
}

func (c *MockClient) ReviewCode(ctx context.Context, code string) (string, error) {
	return "‚úÖ Mock Review: Code looks good! No issues found.", nil
}

func (c *MockClient) GenerateCodeStream(ctx context.Context, prompt string, callback func(chunk string) error) error {
	chunks := []string{
		"// Generating code...\n",
		"package com.example;\n\n",
		"public class Demo {\n",
		"    public static void main(String[] args) {\n",
		"        System.out.println(\"Hello\");\n",
		"    }\n",
		"}\n",
	}

	for _, chunk := range chunks {
		select {
		case <-ctx.Done():
			return ctx.Err()
		default:
		}

		if err := callback(chunk); err != nil {
			return err
		}

		// Ïã§ÏãúÍ∞Ñ Ïä§Ìä∏Î¶¨Î∞ç ÏãúÎÆ¨Î†àÏù¥ÏÖò
		time.Sleep(100 * time.Millisecond)
	}

	return nil
}

// ============================================================================
// Client Factory - ÌôòÍ≤Ω Î≥ÄÏàòÏóê Îî∞Îùº Ï†ÅÏ†àÌïú ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±
// ============================================================================

func NewClient() Client {
	// Í∞ïÏ†úÎ°ú Mock ÏÇ¨Ïö©
	if os.Getenv("OLLAMA_MOCK") == "true" {
		fmt.Println("üìã Using Mock Client (OLLAMA_MOCK=true)")
		return NewMockClient()
	}

	// Ïã§Ï†ú Ollama ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏãúÎèÑ
	ollama := NewOllamaClient()

	// Ïó∞Í≤∞ Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏ (Ìó¨Ïä§ Ï≤¥ÌÅ¨)
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	healthCheckReq, _ := http.NewRequestWithContext(ctx, "GET", ollama.baseURL+"/api/tags", nil)
	resp, err := ollama.client.Do(healthCheckReq)
	if err == nil && resp.StatusCode == http.StatusOK {
		resp.Body.Close()
		fmt.Printf("‚úÖ Ollama connected at %s (model: %s)\n", ollama.baseURL, ollama.model)
		return ollama
	}

	if resp != nil {
		resp.Body.Close()
	}

	// Ollama Ïó∞Í≤∞ Ïã§Ìå® Ïãú MockÏúºÎ°ú Ìè¥Î∞±
	fmt.Printf("‚ö†Ô∏è  Ollama not available at %s, falling back to Mock Client\n", ollama.baseURL)
	return NewMockClient()
}
